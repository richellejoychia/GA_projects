{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63549b1e-db73-404a-9cca-b8d5bbe556ea",
   "metadata": {},
   "source": [
    "# Project 3(5b): NLP Sentiment Analysis - Hugging Face Model 2\n",
    "\n",
    "Done by: Richelle-Joy Chia, a Redditor-and-data-science enthusiast! \n",
    "\n",
    "\n",
    "Problem statement: Through natural language processing and classification models, how can we help Reddit and other interested parties classify posts based on the texts used by people who may be depressed or anxious? Furthermore, how can sentiment analysis be utilized to detect emotions associated with depression and anxiety?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061502d8",
   "metadata": {},
   "source": [
    "## Hugging Face - Model 2 (arpanghoshal/EmoRoBERTa)\n",
    "\n",
    "This model classifies emotions into 28 emotions, which includes primary and secondary emotions. \n",
    "- https://huggingface.co/arpanghoshal/EmoRoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "862f2f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from transformers import RobertaTokenizerFast, TFRobertaForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fe454d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "\n",
    "data = pd.read_csv('../data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22dd5b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows that have been affected by transforming pd df to csv\n",
    "\n",
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "982d4363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# run pipeline to activate model 2 (in this scenario, scores refer to the probability of the emotion occuring, which will be used as the metric) \n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n",
    "model = TFRobertaForSequenceClassification.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n",
    "\n",
    "emotion = pipeline('sentiment-analysis', \n",
    "                    model='arpanghoshal/EmoRoBERTa', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6e5eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to store the respective scores \n",
    "\n",
    "def emotions(df):\n",
    "    labels=[]\n",
    "    scores=[]\n",
    "    for i in tqdm(df['joined_new'], desc = 'tqdm() Progress Bar'):      \n",
    "        index = 0\n",
    "        if index < len(df):\n",
    "            output = emotion([i])\n",
    "            labels.append(output[0]['label'])\n",
    "            scores.append(output[0]['score'])\n",
    "            index += 1\n",
    "    df['labels'] = pd.DataFrame(labels)\n",
    "    df['scores'] = pd.DataFrame(scores)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b311527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tqdm() Progress Bar: 100%|█████████████████████████████████████████████████████| 29969/29969 [2:42:43<00:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 42min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "emotions(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae625ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store df as csv\n",
    "\n",
    "data.to_csv('28emo_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0214b012-24c9-4be7-949d-4bbdfb4ca6c8",
   "metadata": {},
   "source": [
    "## Please proceed on to the next notebook for a more in-depth review on the 2 models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
